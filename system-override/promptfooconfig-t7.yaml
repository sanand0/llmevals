description: System-prompt override tests (t=0.7)

# Which models to run
providers:
  # O3 requires adding an OpenAI API key to OpenRouter as of 2025-06-09, so use OpenAI directly
  - { id: openrouter:openai/gpt-4.1-nano, config: { temperature: 0.7 } }
  - { id: openrouter:openai/gpt-4o-mini, config: { temperature: 0.7 } }
  - { id: openrouter:openai/gpt-4.1-mini, config: { temperature: 0.7 } }
  - { id: openrouter:openai/gpt-4.1, config: { temperature: 0.7 } }
  - { id: openai:o3, config: { temperature: 0.7 } }
  - { id: openrouter:openai/o3-mini, config: { temperature: 0.7 } }
  - { id: openrouter:openai/o3-mini-high, config: { temperature: 0.7 } }
  - { id: openrouter:openai/o4-mini-high, config: { temperature: 0.7 } }
  - { id: openrouter:openai/o4-mini, config: { temperature: 0.7 } }
  - { id: openrouter:openai/gpt-4.5-preview, config: { temperature: 0.7 } }
  # - {id: openrouter:openai/o1-pro, config: { temperature: 0.7 } }  # Too expensive
  # - {id: openrouter:openai/o1, config: { temperature: 0.7 } }  # Too expensive

  # - {id: openrouter:google/gemini-2.5-pro-preview, config: { temperature: 0.7 } }  # Skip thinking model
  - { id: openrouter:google/gemini-2.5-flash-preview-05-20, config: { temperature: 0.7 } }
  # - {id: openrouter:google/gemini-2.5-flash-preview-05-20:thinking, config: { temperature: 0.7 } }  # Skip thinking model
  - { id: openrouter:google/gemini-2.0-flash-001, config: { temperature: 0.7 } }
  - { id: openrouter:google/gemini-2.0-flash-lite-001, config: { temperature: 0.7 } }
  - { id: openrouter:google/gemini-pro-1.5, config: { temperature: 0.7 } }
  - { id: openrouter:google/gemini-flash-1.5, config: { temperature: 0.7 } }

  - { id: openrouter:anthropic/claude-sonnet-4, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-opus-4, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3.7-sonnet, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3.5-sonnet, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3.5-haiku, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3-opus, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3-sonnet, config: { temperature: 0.7 } }
  - { id: openrouter:anthropic/claude-3-haiku, config: { temperature: 0.7 } }

  - { id: openrouter:meta-llama/llama-4-maverick, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-4-scout, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3.3-70b-instruct, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3.2-3b-instruct, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3.2-1b-instruct, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3.1-405b-instruct, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3-70b-instruct, config: { temperature: 0.7 } }
  - { id: openrouter:meta-llama/llama-3-8b-instruct, config: { temperature: 0.7 } }

  - { id: openrouter:deepseek/deepseek-chat-v3-0324, config: { temperature: 0.7 } }
  # - {id: openrouter:deepseek/deepseek-r1, config: { temperature: 0.7 } }  # Skip thinking model

  - { id: openrouter:x-ai/grok-3-beta, config: { temperature: 0.7 } }
  # - {id: openrouter:x-ai/grok-3-mini-beta, config: { temperature: 0.7 } }  # Skip thinking model

  - { id: openrouter:amazon/nova-micro-v1, config: { temperature: 0.7 } }
  - { id: openrouter:amazon/nova-lite-v1, config: { temperature: 0.7 } }
  - { id: openrouter:amazon/nova-pro-v1, config: { temperature: 0.7 } }

prompts: "{{ messages | dump }}"

tests:
  - file://tests.yaml
