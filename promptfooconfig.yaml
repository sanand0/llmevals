# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

description: "Hard Prompts"

providers:
  # Reasoning models need more than the default 1024 tokens
  # O3 requires adding an OpenAI API key to OpenRouter as of 2025-04-26, so use OpenAI directly
  - { id: openai:o3, config: { max_tokens: 8192 } }
  - { id: openrouter:openai/o3-mini-high, config: { max_tokens: 8192 } }
  - { id: openrouter:openai/o4-mini-high, config: { max_tokens: 8192 } }
  - { id: openrouter:openai/o4-mini, config: { max_tokens: 8192 } }
  - { id: openrouter:openai/o3-mini, config: { max_tokens: 8192 } }
  - openrouter:amazon/nova-micro-v1
  - openrouter:amazon/nova-lite-v1
  - openrouter:amazon/nova-pro-v1
  - openrouter:openai/gpt-4.1
  - openrouter:openai/gpt-4.1-mini
  - openrouter:openai/gpt-4.1-nano
  - openrouter:openai/gpt-4.5-preview
  - openrouter:openai/gpt-4o-mini
  - openrouter:google/gemini-2.5-pro-preview-03-25
  - openrouter:google/gemini-2.5-flash-preview
  - openrouter:google/gemini-2.5-flash-preview:thinking
  - openrouter:anthropic/claude-3.7-sonnet:thinking
  - openrouter:anthropic/claude-3.5-haiku
  - openrouter:anthropic/claude-3.5-sonnet
  - openrouter:meta-llama/llama-4-maverick
  - openrouter:meta-llama/llama-4-scout
  - openrouter:deepseek/deepseek-chat-v3-0324
  - openrouter:deepseek/deepseek-r1

tests:
  - description: Caesar cipher
    vars:
      prompt: Gr brx vshdn Fdhvdu flskhu?
    assert:
      - type: llm-rubric
        value: Identifies that the text is in Caesar cipher
      - type: llm-rubric
        value: Either translates it correctly to 'Do you speak Caesar cipher' OR replies to the question in Caesar cipher
        # provider: openai:gpt-4.1
  - description: Python - Append vs Extend
    # https://nicholas.carlini.com/writing/2024/evaluation_examples/fix_append_vs_extend.html
    vars:
      prompt: |
        Why won't this function work as expected? List exactly one reason.

        ```python
        def make_op_with_history(config):
            how = config[0]
            args = config[1:]

            if how.split()[0] == 'dot_from_papers':
                return [(how, make_op(config))]
            if how.split()[0] in ['const_add', 'const_mul']:
                return [(how, make_op(config))] + make_op_with_history(config[1])
            out = []
            for arg in args:
                hist = make_op_with_history(arg)
                out.append(hist)
            return [(how, make_op(config))] + out
        ```
    assert:
      - type: llm-rubric
        value: Response indicates that the code failed because it used append instead of extend.
  - description: ...
    # https://nicholas.carlini.com/writing/2024/evaluation_examples/fix_torch_backward.html
    vars:
      prompt: |
        Explain the bug in this code.

        ```
        import torch
        import torch.nn as nn
        import torch.optim as optim

        class SimpleNet(nn.Module):
            def __init__(self):
                super(SimpleNet, self).__init__()
                self.fc = nn.Linear(1, 1)

            def forward(self, x):
                return self.fc(x)

        def PGD(model, input, target, loss_fn, epsilon, alpha, num_iter):
            perturbation = torch.zeros_like(input, requires_grad=True)

            for i in range(num_iter):
                output = model(input + perturbation)
                loss = loss_fn(output, target)

                loss.backward()

                # Update perturbation
                perturbation_grad = perturbation.grad.data
                perturbation.data = perturbation.data + alpha * perturbation_grad.sign()
                perturbation.data = torch.clamp(perturbation.data, -epsilon, epsilon)
                perturbation.grad.data.zero_()

            return input + perturbation

        model = SimpleNet()

        input = torch.tensor([[1.0]], requires_grad=True)
        target = torch.tensor([[2.0]])

        loss_fn = nn.MSELoss()

        epsilon = 0.1
        alpha = 0.01
        num_iter = 2

        adversarial_input = PGD(model, input, target, loss_fn, epsilon, alpha, num_iter)
        print("Resulting advex", adversarial_input)
        ```
    assert:
      - type: llm-rubric
        value: Response indicates that the bug is caused by not zeroing the gradient in the backward pass.

writeLatestResults: true

commandLineOptions:
  cache: true
